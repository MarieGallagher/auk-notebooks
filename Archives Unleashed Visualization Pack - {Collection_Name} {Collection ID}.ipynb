{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://cloud.archivesunleashed.org/assets/logo-8d2126e162dc682078284bb8f5585e4365fbad6dc04aa2afbae747626bd815ea.png\" height=\"100px\" width=\"100px\">\n",
    "\n",
    "# Welcome\n",
    "\n",
    "Welcome to the Archives Unleashed Cloud Visualization Demo in Jupyter Notebook for your collection { Collection Name } id { Collection Id }. \n",
    "\n",
    "This demonstration takes the main derivatives from the Archives Unleashed Cloud and uses some common Python data analysis approaches to produce some basic information about the collection you provided.\n",
    "\n",
    "This product is in beta, so if you encounter any issues, please post an [issue in our Github repository](https://github.com/archivesunleashed/auk/issues) to let us know what went wrong.\n",
    "\n",
    "If you have some basic Python coding experience, you can change the code we provided to suit your own needs.\n",
    "\n",
    "### How Jupyter Notebooks Work:\n",
    "\n",
    "If you have no previous experience of Jupyter Notebooks, the most important thing to understand is that that <Shift><Enter/Return> will run the python code inside a window and output it to the site.\n",
    "    \n",
    "The window titled `\"#RUN THIS FIRST\"` should be the first place you go. This will import all the libraries and set basic variables (eg. where your derivative files are located) for the notebook. After that, everything else should be able to run on its own.\n",
    "\n",
    "Unfortunately, we cannot support code that you produced yourself. We recommend that you use `File > Make a Copy` first before changing the code in the repository. That way, you can always return to the basic visualizations we have offered here. Of course, you can also just re-download the Jupyter Notebook service from your Archives Unleashed Cloud account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS FIRST\n",
    "# This Window will set up all the necessary libraries and dependencies\n",
    "# for your Collection.\n",
    "coll_id = \"4656\"\n",
    "auk_fp = \"data/\"\n",
    "auk_full_text = auk_fp + coll_id + \"-fulltext.txt\"\n",
    "auk_gephi = auk_fp + \"coll_id-gephi.gexf\"\n",
    "auk_graphml = auk_fp + \"coll_id-gephi.grapml\"\n",
    "auk_domains = auk_fp + \"coll_id-fullurls.txt\"\n",
    "auk_filtered_text = auk_fp + \"coll_id-filtered_text.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.7/site-packages (19.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (3.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.15.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/Cellar/ipython/6.5.0/libexec/vendor/lib/python3.7/site-packages (from matplotlib) (2.7.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (40.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Cellar/ipython/6.5.0/libexec/vendor/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.11.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/Cellar/ipython/6.5.0/libexec/vendor/lib/python3.7/site-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/site-packages (from pandas) (2018.5)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/site-packages (from pandas) (1.15.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Cellar/ipython/6.5.0/libexec/vendor/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.15.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/site-packages (3.4)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/ipython/6.5.0/libexec/vendor/lib/python3.7/site-packages (from nltk) (1.11.0)\n",
      "Requirement already satisfied: singledispatch in /usr/local/lib/python3.7/site-packages (from nltk) (3.4.0.3)\n"
     ]
    }
   ],
   "source": [
    "# The following script will attempt to install the necessary dependencies\n",
    "# for the visualisations. You may prefer to install these on your\n",
    "# own in the command line.\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install -U pip\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ryandeschamps/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import wordcloud as wc\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis\n",
    "\n",
    "The following function uses the nltk python library to search for the top most used words in the collection. Depending on the size of the text file, it may take a while to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(65230, 'News'),\n",
       " (53730, 'Sports'),\n",
       " (36362, 'Business'),\n",
       " (36310, 'Entertainment'),\n",
       " (34680, 'World'),\n",
       " (30811, 'Nanaimo'),\n",
       " (29916, 'with'),\n",
       " (26662, '2016'),\n",
       " (26333, 'Classifieds'),\n",
       " (26102, 'Daily'),\n",
       " (25582, 'updated'),\n",
       " (23951, '2015'),\n",
       " (21342, 'Canada'),\n",
       " (19939, 'Letters'),\n",
       " (19834, 'Home'),\n",
       " (19822, 'About'),\n",
       " (19813, 'Team'),\n",
       " (19758, 'Info'),\n",
       " (19700, 'Jobs'),\n",
       " (19684, 'Contact'),\n",
       " (19671, 'Advertising'),\n",
       " (19669, 'Opinion'),\n",
       " (19666, 'Careers'),\n",
       " (18813, 'Press'),\n",
       " (18760, 'Vancouver'),\n",
       " (17902, 'Games'),\n",
       " (16982, 'Black'),\n",
       " (16871, 'What'),\n",
       " (16612, 'Town'),\n",
       " (16580, 'Guide')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can change the value of top to get more results.\n",
    "# Citation for nltk library: \n",
    "top = 30\n",
    "def get_top_tokens(total=20):\n",
    "    tokens = []\n",
    "    with open (auk_full_text) as fin:\n",
    "        for line in fin:\n",
    "            tokens += word_tokenize(line)\n",
    "    tokens = [(value, key) for key, value in Counter(tokens).items()]\n",
    "    tokens = list(filter(lambda x : len(x[1]) > 3, tokens))\n",
    "    tokens.sort(reverse=True)\n",
    "    return(tokens[0:total])\n",
    "\n",
    "get_top_tokens(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "\n",
    "Bird, Steven, Edward Loper and Ewan Klein (2009), *Natural Language       Processing with Python*. Oâ€™Reilly Media Inc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
