{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://cloud.archivesunleashed.org/assets/logo-8d2126e162dc682078284bb8f5585e4365fbad6dc04aa2afbae747626bd815ea.png\" height=\"100px\" width=\"100px\">\n",
    "\n",
    "# Welcome\n",
    "\n",
    "Welcome to the Archives Unleashed Cloud (AUK) Visualization Demo in Jupyter Notebook for your collection { Collection Name } id { Collection Id }. \n",
    "\n",
    "This demonstration takes the main derivatives from AUK and uses Python data analysis approaches to produce information about the collection you analysed.\n",
    "\n",
    "This product is in beta, so if you encounter any issues, please post an [issue in our Github repository](https://github.com/archivesunleashed/auk/issues) to let us know about any bugs you encountered or features you would like to see included.\n",
    "\n",
    "If you have some basic Python coding experience, you can change the code we provided to suit your own needs. Unfortunately, we cannot support code that you produced yourself. We recommend that you use `File > Make a Copy` first before changing the code in the repository. That way, you can always return to the basic visualizations we have offered here. Of course, you can also just re-download the Jupyter Notebook service from your Archives Unleashed Cloud account.\n",
    "\n",
    "### How Jupyter Notebooks Work:\n",
    "\n",
    "If you have no previous experience of Jupyter Notebooks, the most important thing to understand is that that <Shift><Enter/Return> will run the python code inside a window and output it to the site.\n",
    "    \n",
    "The window titled `# RUN THIS FIRST` should be the first place you go. This will import all the libraries and set basic variables (eg. where your derivative files are located) for the notebook. After that, everything else should be able to run on its own.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS FIRST\n",
    "\n",
    "# This Window will set up all the necessary libraries and dependencies\n",
    "# for your Collection.\n",
    "coll_id = \"4656\"\n",
    "auk_fp = \"data/\"\n",
    "auk_full_text = auk_fp + coll_id + \"-fulltext.txt\"\n",
    "auk_gephi = auk_fp + \"coll_id-gephi.gexf\"\n",
    "auk_graphml = auk_fp + \"coll_id-gephi.grapml\"\n",
    "auk_domains = auk_fp + \"coll_id-fullurls.txt\"\n",
    "auk_filtered_text = auk_fp + \"coll_id-filtered_text.zip\"\n",
    "\n",
    "# The following script will attempt to install the necessary dependencies\n",
    "# for the visualisations. You may prefer to install these on your\n",
    "# own in the command line.\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "try:  # a library for manipulating column data.\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install pandas  \n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt # a library for Plotting\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install matplotlib\n",
    "\n",
    "try:\n",
    "    import numpy as np # a library for complex mathematics\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install numpy\n",
    "    \n",
    "try:\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.draw.dispersion import dispersion_plot as dp\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install nltk\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis\n",
    "\n",
    "The following set of functions use the nltk python library to search for the top most used words in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the value of `top` to get more results. \n",
    "top = 30\n",
    "\n",
    "def clean_domain(s):\n",
    "    stop_words = [\"com\", \"org\", \"net\", \"edu\"]\n",
    "    ret = \"\"\n",
    "    dom = s.split(\".\")\n",
    "    if len(dom) <3:\n",
    "        ret = dom[0]\n",
    "    elif dom[-2] in stop_words:\n",
    "        ret = dom[-3]\n",
    "    else:\n",
    "        ret = dom[1]\n",
    "    return ret\n",
    "\n",
    "def get_textfile () :\n",
    "    tokens = []\n",
    "    with open (auk_full_text) as fin:\n",
    "        for line in fin:\n",
    "            tokens += word_tokenize(str(line).split(\",\")[3])\n",
    "    return tokens\n",
    "\n",
    "def get_text_domains():\n",
    "    tokens = []\n",
    "    with open (auk_full_text) as fin:\n",
    "        for line in fin:\n",
    "            split_line = str(line).split(',')\n",
    "            tokens.append((clean_domain(split_line[1]), split_line[3]))\n",
    "    return tokens\n",
    "\n",
    "def get_text_years():\n",
    "    tokens = []\n",
    "    with open (auk_full_text) as fin:\n",
    "        for line in fin:\n",
    "            split_line = str(line).split(',')\n",
    "            tokens.append((split_line[0][1:5], split_line[3]))\n",
    "    return tokens\n",
    "\n",
    "def get_top_tokens(total=20):\n",
    "    tokens = get_textfile()\n",
    "    tokens = [(value, key) for key, value in Counter(tokens).items()]\n",
    "    tokens = list(filter(lambda x : len(x[1]) > 3, tokens))\n",
    "    tokens.sort(reverse=True)\n",
    "    return(tokens[0:total])\n",
    "\n",
    "def get_top_tokens_by_year(total=20):\n",
    "    tokens = get_text_years()\n",
    "    sep = {key: \"\" for key, value in tokens}\n",
    "    for year, text in tokens:\n",
    "        sep[str(year)] = sep[str(year)] + \" \" + text\n",
    "    ret = [(key, Counter(word_tokenize(val)).most_common(total)) for key, val in sep.items()]\n",
    "    return (ret)\n",
    "\n",
    "def get_top_tokens_by_domain(total=20):\n",
    "    tokens = get_text_domains()\n",
    "    sep = {key: \"\" for key, value in tokens}\n",
    "    for domain, text in tokens:\n",
    "        sep[str(domain)] = sep[str(domain)] + \" \" + text\n",
    "    ret = [(key, Counter(word_tokenize(val)).most_common(total)) for key, val in sep.items()]\n",
    "    return (ret)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have saved the above functions, you can now use them like so:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the set of available years in the collection \n",
    "set([x[0] for x in get_text_years()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the top words in the collection\n",
    "# (regardless of year).\n",
    "get_top_tokens(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the top tokens, separated by year.\n",
    "get_top_tokens_by_year(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bcdailybuzz',\n",
       "  [(')', 8),\n",
       "   ('Not', 8),\n",
       "   ('Found', 8),\n",
       "   ('404', 4),\n",
       "   ('The', 4),\n",
       "   ('requested', 4),\n",
       "   ('URL', 4),\n",
       "   ('was', 4),\n",
       "   ('not', 4),\n",
       "   ('found', 4),\n",
       "   ('on', 4),\n",
       "   ('this', 4),\n",
       "   ('server', 4),\n",
       "   ('.', 4),\n",
       "   ('/thumbs/c3e0677be2f6.jpg', 1),\n",
       "   ('/thumbs/575280c2a866.jpg', 1),\n",
       "   ('/thumbs/6a5e80c11f3d.jpg', 1),\n",
       "   ('/thumbs/eb55c88d287c.png', 1)]),\n",
       " ('nanaimodailynews',\n",
       "  [('BC', 58638),\n",
       "   ('News', 32906),\n",
       "   ('Sports', 26951),\n",
       "   ('World', 17705),\n",
       "   ('Our', 17554),\n",
       "   ('Business', 17512),\n",
       "   ('Entertainment', 17502),\n",
       "   ('Us', 14803),\n",
       "   ('Classifieds', 14711),\n",
       "   ('-', 13487),\n",
       "   ('Nanaimo', 13461),\n",
       "   ('Daily', 13125),\n",
       "   (\"'s\", 10501),\n",
       "   ('on', 10120),\n",
       "   ('Canada', 9244),\n",
       "   ('Games', 8830),\n",
       "   ('Vancouver', 8823),\n",
       "   ('Team', 8794),\n",
       "   ('Letters', 8779),\n",
       "   ('Home', 8777),\n",
       "   ('Contact', 8776),\n",
       "   ('Jobs', 8771),\n",
       "   ('Advertising', 8768),\n",
       "   ('Info', 8764),\n",
       "   ('Opinion', 8764),\n",
       "   ('Browse', 8758),\n",
       "   ('Opinions', 8755),\n",
       "   ('Poll', 8753),\n",
       "   ('Guide', 8740),\n",
       "   ('NFL', 8713)]),\n",
       " ('google',\n",
       "  [('Â·', 3),\n",
       "   ('Whidbey', 2),\n",
       "   ('News-Times', 2),\n",
       "   ('Maps', 2),\n",
       "   ('Help', 2),\n",
       "   ('Feedback', 2),\n",
       "   ('Profile', 2),\n",
       "   ('Terms', 2),\n",
       "   ('-', 1),\n",
       "   ('Google+', 1),\n",
       "   ('Search', 1),\n",
       "   ('Images', 1),\n",
       "   ('Play', 1),\n",
       "   ('YouTube', 1),\n",
       "   ('News', 1),\n",
       "   ('Gmail', 1),\n",
       "   ('Drive', 1),\n",
       "   ('More', 1),\n",
       "   ('Calendar', 1),\n",
       "   ('Translate', 1),\n",
       "   ('Mobile', 1),\n",
       "   ('Books', 1),\n",
       "   ('Wallet', 1),\n",
       "   ('Shopping', 1),\n",
       "   ('Blogger', 1),\n",
       "   ('Finance', 1),\n",
       "   ('Photos', 1),\n",
       "   ('Videos', 1),\n",
       "   ('Docs', 1),\n",
       "   ('Even', 1)]),\n",
       " ('facebook',\n",
       "  [('Facebook', 2),\n",
       "   ('the', 2),\n",
       "   ('.', 2),\n",
       "   ('Cross-Domain', 1),\n",
       "   ('Messaging', 1),\n",
       "   ('helper', 1),\n",
       "   ('SECURITY', 1),\n",
       "   ('WARNING', 1),\n",
       "   (':', 1),\n",
       "   ('Please', 1),\n",
       "   ('treat', 1),\n",
       "   ('URL', 1),\n",
       "   ('above', 1),\n",
       "   ('as', 1),\n",
       "   ('you', 1),\n",
       "   ('would', 1),\n",
       "   ('your', 1),\n",
       "   ('password', 1),\n",
       "   ('and', 1),\n",
       "   ('do', 1),\n",
       "   ('not', 1),\n",
       "   ('share', 1),\n",
       "   ('it', 1),\n",
       "   ('with', 1),\n",
       "   ('anyone', 1),\n",
       "   ('See', 1),\n",
       "   ('Help', 1),\n",
       "   ('Center', 1),\n",
       "   ('for', 1),\n",
       "   ('more', 1)]),\n",
       " ('googlesyndication', [('SafeFrame', 1), ('Container', 1), (')', 1)]),\n",
       " ('save',\n",
       "  [('LOADING', 10),\n",
       "   ('&', 10),\n",
       "   ('nbspFLYER', 10),\n",
       "   ('-', 3),\n",
       "   ('Found', 2),\n",
       "   (')', 2),\n",
       "   ('Save.ca', 2),\n",
       "   ('302', 1),\n",
       "   ('The', 1),\n",
       "   ('document', 1),\n",
       "   ('has', 1),\n",
       "   ('moved', 1),\n",
       "   ('here', 1),\n",
       "   ('.', 1),\n",
       "   ('Coupons', 1),\n",
       "   ('and', 1),\n",
       "   ('Deals', 1),\n",
       "   ('For', 1),\n",
       "   ('All', 1),\n",
       "   ('of', 1),\n",
       "   ('Canada', 1),\n",
       "   ('ExternalWidget', 1),\n",
       "   ('Flyers', 1),\n",
       "   ('WEEKLY', 1),\n",
       "   ('FLYERS', 1)]),\n",
       " ('schema',\n",
       "  [('schema.org', 8),\n",
       "   ('a', 5),\n",
       "   ('Home', 4),\n",
       "   ('-', 4),\n",
       "   ('Documentation', 4),\n",
       "   ('Schemas', 4),\n",
       "   ('>', 4),\n",
       "   ('JobPosting', 3),\n",
       "   ('Thing', 3),\n",
       "   ('Organization', 3),\n",
       "   ('Place', 3),\n",
       "   ('Schema.org', 2),\n",
       "   ('that', 2),\n",
       "   ('organization', 2),\n",
       "   ('About', 1),\n",
       "   ('Welcome', 1),\n",
       "   ('to', 1),\n",
       "   ('is', 1),\n",
       "   ('collaborative', 1),\n",
       "   ('Intangible', 1),\n",
       "   ('A', 1),\n",
       "   ('listing', 1),\n",
       "   ('describes', 1),\n",
       "   ('job', 1),\n",
       "   ('opening', 1),\n",
       "   ('in', 1),\n",
       "   ('certain', 1),\n",
       "   ('.', 1),\n",
       "   ('Usage', 1),\n",
       "   (':', 1)]),\n",
       " ('accuweather',\n",
       "  [('AccuWeather.com', 1),\n",
       "   ('Weather', 1),\n",
       "   ('Canadian', 1),\n",
       "   ('Cities', 1),\n",
       "   (':', 1),\n",
       "   ('International', 1),\n",
       "   ('Locations', 1),\n",
       "   ('Vancouver', 1)]),\n",
       " ('issuu',\n",
       "  [('Nanaimo', 89),\n",
       "   ('Daily', 89),\n",
       "   ('News', 89),\n",
       "   ('.', 58),\n",
       "   (')', 54),\n",
       "   ('to', 50),\n",
       "   ('Moved', 48),\n",
       "   ('Permanently', 48),\n",
       "   ('Redirecting', 48),\n",
       "   (':', 46),\n",
       "   ('https', 42),\n",
       "   ('?', 39),\n",
       "   ('mode=mobile', 21),\n",
       "   ('mobile=true', 16),\n",
       "   ('issuu', 10),\n",
       "   ('-', 9),\n",
       "   ('Black', 8),\n",
       "   ('Press', 8),\n",
       "   ('Sign', 8),\n",
       "   ('publisher', 8),\n",
       "   ('Special', 6),\n",
       "   ('Features', 6),\n",
       "   ('Plans', 6),\n",
       "   ('http', 4),\n",
       "   ('Explore', 4),\n",
       "   ('Publisher', 4),\n",
       "   ('In', 4),\n",
       "   ('&', 4),\n",
       "   ('Follow', 4),\n",
       "   ('Unfollow', 4)]),\n",
       " ('googleapis',\n",
       "  [('.', 4),\n",
       "   ('404', 2),\n",
       "   (')', 2),\n",
       "   ('!', 2),\n",
       "   ('That', 2),\n",
       "   ('â', 2),\n",
       "   ('s', 2),\n",
       "   ('Error', 1),\n",
       "   ('(', 1),\n",
       "   ('Not', 1),\n",
       "   ('Found', 1),\n",
       "   ('1', 1),\n",
       "   ('an', 1),\n",
       "   ('error', 1),\n",
       "   ('The', 1),\n",
       "   ('requested', 1),\n",
       "   ('URL', 1),\n",
       "   ('was', 1),\n",
       "   ('not', 1),\n",
       "   ('found', 1),\n",
       "   ('on', 1),\n",
       "   ('this', 1),\n",
       "   ('server', 1),\n",
       "   ('all', 1),\n",
       "   ('we', 1),\n",
       "   ('know', 1)]),\n",
       " ('blackpress',\n",
       "  [('Media', 4),\n",
       "   ('Management', 4),\n",
       "   ('Black', 3),\n",
       "   ('Press', 3),\n",
       "   ('Download', 3),\n",
       "   ('Kit', 3),\n",
       "   ('Us', 3),\n",
       "   ('Sales', 2),\n",
       "   ('Our', 2),\n",
       "   ('About', 2),\n",
       "   ('â', 1),\n",
       "   ('Community', 1),\n",
       "   ('News', 1),\n",
       "   ('Home', 1),\n",
       "   ('Publications', 1),\n",
       "   ('Advertising', 1),\n",
       "   ('Solutions', 1),\n",
       "   ('Classified', 1),\n",
       "   ('National', 1),\n",
       "   ('Team', 1),\n",
       "   ('FLYER', 1),\n",
       "   ('DIGITAL', 1),\n",
       "   ('ROP', 1),\n",
       "   ('Printing', 1),\n",
       "   ('Executives', 1),\n",
       "   ('B.C', 1),\n",
       "   ('.', 1),\n",
       "   ('U.S.', 1),\n",
       "   ('Alta', 1),\n",
       "   ('Company', 1)])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_tokens_by_domain(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dispersion plot, showing where the list of words appear\n",
    "# in the text.\n",
    "text = get_textfile()\n",
    "dp(text, [\"he\", \"she\"]) # uses the nltk dispersion plot library (dp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "\n",
    "Bird, Steven, Edward Loper and Ewan Klein (2009), *Natural Language       Processing with Python*. OâReilly Media Inc.\n",
    "\n",
    "Archives Unleashed Project. (2018). Archives Unleashed Toolkit (Version 0.17.0). Apache License, Version 2.0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
